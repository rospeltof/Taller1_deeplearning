{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8282c627",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf89e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5aad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura la longitud de la secuencia y el horizonte de predicción\n",
    "sequence_length = 24  #  24 pasos (2h 24min)\n",
    "horizon = 1           # Predicción 1 paso adelante\n",
    "\n",
    "# Función para crear ventanas de tiempo\n",
    "def create_dataset(X, y, sequence_length=24, horizon=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - sequence_length - horizon + 1):\n",
    "        Xs.append(X[i:(i + sequence_length)])\n",
    "        ys.append(y[i + sequence_length + horizon - 1])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "971edb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "X_train_path = os.path.join('..', 'data', 'processed', 'X_train.csv')\n",
    "X_test_path = os.path.join('..', 'data', 'processed', 'X_test.csv')\n",
    "y_train_path = os.path.join('..', 'data', 'processed', 'y_train.csv')\n",
    "y_test_path = os.path.join('..', 'data', 'processed', 'y_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a0cfca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\processed\\X_test.csv\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(X_test_path)\n",
    "print(os.path.exists(X_test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "483a977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = pd.read_csv(X_train_path)\n",
    "X_test = pd.read_csv(X_test_path)\n",
    "y_train = pd.read_csv(y_train_path)\n",
    "y_test = pd.read_csv(y_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e14a183",
   "metadata": {},
   "source": [
    "Despues de cargados los dataframes vamos a construir el modelo con Keras, trataremos de predecir en simultaneo la temperatura y precipitación usando una RNN\n",
    "\n",
    "Primero nos aseguraremos que las dimensiones de los dataframes sean las adecuadas.\n",
    "\n",
    "N_features hace referencia a la cantidad de variables categoricas que miden en cada paso con el paso del tiempo. que en nuestro caso será 9 pues son viene dado por las columnas : dd\n",
    "\n",
    "ff\n",
    "\n",
    "hu\n",
    "\n",
    "td\n",
    "\n",
    "month\n",
    "\n",
    "quarter\n",
    "\n",
    "dd_rad\n",
    "\n",
    "wind_u\n",
    "\n",
    "wind_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0daa2d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_features = X_train.shape[1]  # 9 características (excluyendo 'date')\n",
    "N_timesteps = X_train.shape[1]  # Usaremos la misma cantidad de pasos de tiempo que características (esto depende de cómo formatees tus datos)\n",
    "N_output = 2  # Para predecir temperatura (t) y precipitación (precip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b946114",
   "metadata": {},
   "source": [
    "Usando LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d34bc62",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Crear el modelo\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mmodels\u001b[49m.Sequential()\n",
      "\u001b[31mNameError\u001b[39m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f355d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capa LSTM\n",
    "model.add(layers.LSTM(units=64, return_sequences=False, input_shape=(N_timesteps, N_features)))\n",
    "\n",
    "# Dropout para evitar sobreajuste\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Capa densa para la predicción\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Capa de salida\n",
    "model.add(layers.Dense(N_output))  # Dos salidas: temperatura (t) y precipitación (precip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023aa959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilación del modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Ver resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "# Definir callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56257a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5f5e67",
   "metadata": {},
   "source": [
    "Usando GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0573d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f10215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capa GRU\n",
    "model_gru.add(layers.GRU(units=64, return_sequences=False, input_shape=(N_timesteps, N_features)))\n",
    "\n",
    "# Dropout para evitar sobreajuste\n",
    "model_gru.add(layers.Dropout(0.2))\n",
    "\n",
    "# Capa densa\n",
    "model_gru.add(layers.Dense(64, activation='relu'))\n",
    "model_gru.add(layers.Dropout(0.2))\n",
    "\n",
    "# Capa de salida\n",
    "model_gru.add(layers.Dense(N_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d125ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c1fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_gru = model_gru.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5544d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_gru, test_mae_gru = model_gru.evaluate(X_test, y_test)\n",
    "print(f\"GRU Test loss: {test_loss_gru}\")\n",
    "print(f\"GRU Test MAE: {test_mae_gru}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59317f4b",
   "metadata": {},
   "source": [
    "Haremos una comparación visual mediante graficos de entrenamiento y validacion para ver como se comporta la convergencia de los modelos y tambien su peridda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e69548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar las pérdidas de entrenamiento y validación para LSTM y GRU\n",
    "plt.plot(history.history['loss'], label='LSTM Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='LSTM Validation Loss')\n",
    "plt.plot(history_gru.history['loss'], label='GRU Train Loss')\n",
    "plt.plot(history_gru.history['val_loss'], label='GRU Validation Loss')\n",
    "plt.title('Train vs Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf44f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar los MAE de LSTM y GRU\n",
    "plt.plot(history.history['mae'], label='LSTM Train MAE')\n",
    "plt.plot(history.history['val_mae'], label='LSTM Validation MAE')\n",
    "plt.plot(history_gru.history['mae'], label='GRU Train MAE')\n",
    "plt.plot(history_gru.history['val_mae'], label='GRU Validation MAE')\n",
    "plt.title('Train vs Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
